# 기본 학습 설정
training:
  # 기본 학습 설정
  num_train_epochs: 10
  learning_rate: 1e-4
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  optim: "paged_adamw_8bit"
  
  # 스케줄러 설정
  lr_scheduler_type: "cosine"
  warmup_steps: 100
  
  # 배치 및 메모리 최적화
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  
  # 하드웨어 최적화
  fp16: false
  bf16: true
  
  # 평가 및 저장 전략
  evaluation_strategy: "epoch"
  eval_steps: 500
  save_strategy: "epoch"
  save_steps: 500
  save_total_limit: 1
  load_best_model_at_end: true
  metric_for_best_model: "eval/rouge1_f1"
  greater_is_better: true
  
  # 로깅 설정
  logging_strategy: "steps"
  logging_steps: 100
  logging_first_step: true
  report_to: ["wandb"]
  
  # 생성 설정
  predict_with_generate: true
  remove_unused_columns: true
  generation_max_length: 128
  generation_num_beams: 4
  skip_special_tokens: true
  clean_up_tokenization_spaces: true
  pad_to_max_length: true
  truncation: true
  padding: "max_length"
  ignore_pad_token_for_loss: true
  label_pad_token_id: -100
  
  # 토큰화 설정
  max_source_length: 512
  max_target_length: 128
  num_beams: 4
  length_penalty: 1.0
  no_repeat_ngram_size: 3
  early_stopping: true

# 데이터 전처리 설정
preprocessing:
  enabled: true
  merge_train_dev: true
  split_ratio: 0.2
  stratify_column: null
  stratify_by_length: true
  length_strategy: "ratio"
  length_bins:
    dialogue: 3
    summary: 3
    ratio: 3
  random_state: ${general.seed}
  balance_length: true
  
  # 토큰화 전처리
  max_length: 512
  padding: "max_length"
  truncation: true
  return_tensors: "pt"
  return_attention_mask: true
  add_special_tokens: true
