# 기본 학습 설정
training:
  # 학습 설정
  num_train_epochs: 1
  learning_rate: 1e-4
  
  # Learning rate scheduler 설정
  lr_scheduler_type: "cosine"  # cosine scheduler 사용
  warmup_ratio: 0.1  # 전체 학습의 10%를 warmup에 사용
  
  # 기타 최적화 설정
  weight_decay: 0.01
  max_grad_norm: 1.0
  optim: "paged_adamw_8bit"
  
  # 배치 및 메모리 최적화
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  
  # 하드웨어 최적화
  fp16: false
  bf16: true
  
  # 평가 및 저장 전략
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 1
  load_best_model_at_end: true
  metric_for_best_model: "eval/rouge1_f1"
  greater_is_better: true
  
  # 로깅 관련 설정
  logging_strategy: "steps"  # 또는 "epoch"
  logging_steps: 10         # 로깅 주기
  logging_first_step: true
  logging_dir: "${general.output_path}/logs"
  report_to: ["wandb", "tensorboard"]  # wandb와 tensorboard 모두 사용
  
  # 생성 관련
  predict_with_generate: true
  remove_unused_columns: true
  generation_max_length: ${model.generation.max_new_tokens}
  generation_num_beams: ${model.generation.num_beams}
