name: "gogamza/kobart-summarization"
mode: "finetune"
family: "bart"

tokenizer:
  max_length: 1024
  padding: "max_length"
  truncation: true
  return_tensors: "pt"
  padding_side: "right"
  truncation_side: "right"
  encoder_max_len: 1024
  decoder_max_len: 128
  bos_token_id: 0
  decoder_start_token_id: 0

generation:
  max_length: 128
  max_new_tokens: 128
  min_new_tokens: 32
  temperature: 0.7
  top_p: 0.9
  do_sample: true
  num_beams: 4
  length_penalty: 1.0
  repetition_penalty: 1.2
  no_repeat_ngram_size: 3
  early_stopping: true
  bos_token_id: 0
  decoder_start_token_id: 0
  eos_token_id: 1

# 학습 설정
train:
  training:
    num_train_epochs: 3
    learning_rate: 5e-5
    warmup_ratio: 0.1
    weight_decay: 0.01
    
    per_device_train_batch_size: 8
    per_device_eval_batch_size: 8
    gradient_accumulation_steps: 4
    gradient_checkpointing: true
    
    evaluation_strategy: "epoch"
    save_strategy: "epoch"
    save_total_limit: 2
    load_best_model_at_end: true
    metric_for_best_model: "eval_rouge1_f1"
    greater_is_better: true
    
    logging_steps: 10
    logging_first_step: true
    
    predict_with_generate: true
    remove_unused_columns: true

model:
  trust_remote_code: true
  device_map: "auto" 