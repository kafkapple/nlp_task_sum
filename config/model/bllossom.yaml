name: "MLP-KTLim/llama-3-Korean-Bllossom-8B"
family: "llama"
mode: "finetune"

# 모델 특화 설정
trust_remote_code: true
torch_dtype: "float16"
device_map: "auto"

# 토크나이저 설정
tokenizer:
  max_length: 512
  padding_side: "left"
  truncation_side: "left"
  padding: "max_length"
  truncation: true
  return_tensors: "pt"
  encoder_max_len: 256
  decoder_max_len: 128

# 생성 설정
generation:
  num_beams: 5
  max_new_tokens: 200
  min_new_tokens: 50
  length_penalty: 0.8
  repetition_penalty: 2.0
  no_repeat_ngram_size: 3
  early_stopping: true
  temperature: 0.8
  top_p: 0.9
  top_k: 50
  do_sample: true
  length_ratio: 0.2  # 입력 길이 대비 생성 길이 비율

# 양자화 설정
quantization:
  enabled: true
  precision: "int4"
  compute_dtype: "float16"
  double_quant: true
  quant_type: "nf4"

# LoRA 설정
lora:
  enabled: true
  r: 4
  alpha: 16
  dropout: 0.1
  target_modules: "q_proj,v_proj"
  task_type: "CAUSAL_LM"
  bias: "none"
  modules_to_save: null
  fan_in_fan_out: false
  inference_mode: false

# Few-shot 설정 (t5.yaml 참고)
prompt:
  mode: "few-shot"
  n_samples: 1
  selection:
    method: "random"
    seed: ${general.seed}

# 학습 설정
train:
  training:
    per_device_train_batch_size: 1
    per_device_eval_batch_size: 1
    gradient_accumulation_steps: 16
    gradient_checkpointing: true
    
    fp16: true
    bf16: false
    optim: "adamw_torch"
    max_grad_norm: 0.3
    
    save_strategy: "epoch"
    save_total_limit: 2
 