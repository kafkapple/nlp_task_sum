name: "lwef/llama3-8B-ko-dialogue-summary-finetuned"
family: "llama"
mode: "prompt"

# 토크나이저 설정
tokenizer:
  max_length: 2048
  padding_side: "left"
  truncation_side: "left"

# 모델 설정
model:
  trust_remote_code: true
  torch_dtype: "float16"
  device_map: "auto"

# 생성 설정
generation:
  max_new_tokens: 32
  min_length: 10
  temperature: 0.3
  top_p: 0.9
  repetition_penalty: 1.2
  no_repeat_ngram_size: 3
  num_beams: 5
  length_penalty: 1.0
  stop_sequences: [
    "###", "대화", "Summary:", "Dialogue:", 
    "아래 대화를", "다음 대화를", "#",
    "대화 형식은", "요약해 주세요",
    "Instructions:", "지시사항:", "Rules:",
    ">>>"
  ]
  bad_words: [
    "Person1", "Person2", "The", "In", "This", 
    "It", "They", "We", "You", "He", "She",
    "instruction", "template", "prompt"
  ]

# 양자화 설정
quantization:
  enabled: true
  precision: "int4"
  compute_dtype: "float16"

# LoRA 설정
lora:
  r: 8
  alpha: 32
  dropout: 0.1
  target_modules: ["q_proj", "v_proj"] 