defaults:
  - _self_
  - model: t5
  - train: train
prompt:
  mode: "few-shot"
  version: "v2"
  use_in_train: false  # 학습 시 프롬프트 사용 여부
  use_in_inference: true  # 추론 시 프롬프트 사용 여부
  n_samples: 2
  save_predictions: true
  system: "You are a expert in the field of dialogue summarization..."
  instruction: |
    Following the instructions below...
debug:
  enabled: true
  train_samples: 20
  val_samples: 10
prompt_templates:
  "1":
    system: |
      You are a Korean dialogue summarizer. Follow these rules:
      1. Summarize the dialogue in Korean only
      2. Keep the summary concise and simple 
      3. Do not include any English text
      4. Focus on the key points only
      5. Convert colloquial language into formal written language
    instruction: |
      Please summarize the following dialogue in Korean.
      Be concise and focus on the key points.
      Keep it under 100 characters.
    few_shot:
      user: |
        다음 대화를 요약해주세요:
        
        Sample Dialogue:
        {sample_dialogue}
        
        Summary:
      assistant: |
        {sample_summary}
      final_user: |
        Dialogue:
        {dialogue}
        
        Summary:
    zero_shot:
      user: |
        다음 대화를 요약해주세요:
        
        Dialogue:
        {dialogue}
        
        Summary:
  "2":
    system: |
      You are a expert in the field of dialogue summarization, summarize the given dialogue in a concise manner. Follow the user's instruction carefully and provide a summary that is relevant to the dialogue.
      Rules:
      1. Only output the summary, nothing else
      2. Do not include any instructions or markers
      3. Keep it simple and focused
      4. Convert the provided colloquial language into formal written language.
    instruction: |
      Following the instructions below, summarize the given document.
      Instructions:
      1. Read the provided sample dialogue and corresponding summary.
      2. Read the dialogue carefully.
      3. Following the sample's style of summary, provide a concise summary of the given dialogue.
      4. Be sure that the summary is simple but captures the essence of the dialogue.
      5. Keep the summary under 100 characters.
    few_shot:
      user: |
        Following the instructions above, summarize the given document.  아래 대화를 위 예시들과 비슷한 스타일로 요약해주세요
        
        Dialogue:
        {sample_dialogue}
        
        Summary:
      assistant: |
        {sample_summary}
      final_user: |
        Dialogue:
        {dialogue}
        
        Summary:
    zero_shot: |
      Following the instructions above, summarize the given document.
      
      Dialogue: {dialogue}
      
      Summary:

general:
  seed: 42
  timestamp: ${now:%Y%m%d_%H%M%S}
  data_path: "${hydra:runtime.cwd}/data"
  output_path: "outputs/${now:%Y%m%d_%H%M%S}"
  model_cache_dir: "${hydra:runtime.cwd}/../models"
  model_type: "bart"  # 또는 "t5"
  
  wandb:
    project: "dialogue-summary"
    entity: "ailab_upstage_fastcampus"



inference:
  enabled: true
  batch_size: 32
  ckt_path: "${general.output_path}/checkpoint-500"
  
  # 추론시 생성 설정
  max_new_tokens: 200  # max_length 대신 max_new_tokens 사용
  min_new_tokens: 50   # min_length 대신 min_new_tokens 사용
  num_beams: 5
  length_penalty: 0.6
  repetition_penalty: 1.3
  no_repeat_ngram_size: 3
  early_stopping: false
  do_sample: true
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  
  remove_tokens: 
    - "<usr>"
    - "<s>"
    - "</s>"
    - "<pad>"
data:
  split_strategy: "stratified"
  split_ratio: 0.2
  train: "train"
  val: "dev"
url:
  data: "https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000342/data/data.tar.gz"
  code: "https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000342/data/code.tar.gz"

metrics:
  rouge-1: eval/rouge1_f1
  rouge-2: eval/rouge2_f1
  rouge-L: eval/rougeL_f1

huggingface:
  token: ${oc.env:HUGGINGFACE_TOKEN}
  cache_dir: ${general.model_cache_dir}

lora:
  r: 8
  alpha: 32
  dropout: 0.1
  target_modules: ["q_proj", "v_proj"]

common:
  additional_special_tokens:
    - "#PhoneNumber#"
    - "#Address#"
    - "#DateOfBirth#"
    - "#PassportNumber#"
    - "#SSN#"
    - "#CardNumber#"
    - "#CarNumber#"
    - "#Email#" 


custom_config:
  inference: true
  few_shot: true
  n_few_shot_samples: 1
  few_shot_selection: "length"
  n_val_samples: 100
  temperature: 0.3
  max_new_tokens: 150
  top_p: 0.8
  top_k: 50
  do_sample: true
  stop_sequences: ["###", "대화", "Summary:", "Dialogue:"]
